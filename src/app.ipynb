{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essentials\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import json\n",
    "from pickle import dump\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Model\n",
    "#??????\n",
    "\n",
    "#Extras\n",
    "import warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Problem statement and data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Description of the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\"\n",
    "\n",
    "df_download = pd.read_csv(path, sep=\";\")\n",
    "df_download.to_csv(\"../data/rawdata_name.csv\", index=False)\n",
    "\n",
    "df = pd.read_csv(\"../data/raw/data_name.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Understanding the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Our dataframe contains {len(df)} rows and it has {df.shape[1]} features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()[df.isna().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Conclusions:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Eliminating irrelevant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Univariated Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Dividing out dataset into categorical and numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m.\u001b[39munique()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = [\"int64\", \"float64\"]\n",
    "cat = [\"O\"]\n",
    "\n",
    "#Nuemrical df\n",
    "df_num = df.select_dtypes(num)\n",
    "#Categorical df\n",
    "df_cat = df.select_dtypes(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Categorical variable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=??,ncols=??,figsize=(??,??))\n",
    "\n",
    "sns.countplot(ax= ax[0,0], data=df_cat, x=\"??\", order=df_cat[\"??\"].value_counts().index, hue=\"??\")\n",
    "#...\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Conclusions:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Numerical variable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(??, ??, figsize=(10,12), gridspec_kw={\"height_ratios\":[6,1,6,1,6,1,6,1,6,1]})\n",
    "\n",
    "#Row_1\n",
    "sns.histplot(ax = ax[0,0], data=df_num[df_num[\"??\"]], x=\"??\")\n",
    "sns.boxplot(ax = ax[1,0], data=df_num, x=\"??\")\n",
    "#...\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(hspace=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Conclusions:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Multivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Analysis Categorical - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(2, 4, figsize = (16, 14))\n",
    "fig.suptitle(\"Análisis categórico-categórico\", fontsize=16)\n",
    "\n",
    "sns.countplot(ax = axis[0, 0], data = df_cat, x=\"??\", hue = \"TARGET\").set(xlabel= None)\n",
    "axis[0, 0].set_xticklabels(axis[0, 0].get_xticklabels(), rotation=90, fontsize=8)\n",
    "#...\n",
    "\n",
    "axis[0, 0].set_title(\"??\", fontsize=14, fontweight='??')\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Conclusions:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Encoding Categorical Values and saving in JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating encoders for categorical features and saving them as JSON files. All files prefixed with 'enc'\n",
    "# contain the encoding dictionaries for each categorical feature.\n",
    "for column in df_cat.columns:\n",
    "    unique_values = list(df_cat[column].unique())\n",
    "    globals()[f\"{column}_enc\"] = dict(zip(unique_values, range(len(unique_values))))\n",
    "\n",
    "    json.dump(globals()[f\"{column}_enc\"], open(f'../data/interim/enc_{column}.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the values in our categorical features to our encoded values (numerical)\n",
    "for column in df_cat.columns:\n",
    "    df_enc[column] = df_enc[column].map(json.load(open(f'../data/interim/enc_{column}.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Analysis Numerical - Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(??, ??, figsize = (14, 10))\n",
    "\n",
    "sns.regplot(ax = axis[0, 0], data = df_enc, x = \"??\", y = \"TARGET\")\n",
    "sns.heatmap(df_enc[[\"TARGET\", \"??\"]].corr(), annot = True, fmt = \".2f\", ax = axis[1, 0], cbar = False)\n",
    "#...\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.4 Numerical - Categorical analysis (Correlational Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df_enc)\n",
    "plt.savefig(\"Num_cat_corr.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "sns.heatmap(data=df_enc.corr().round(2), annot=True, square= True, cmap=\"RdBu\", mask=np.triu(df_enc.corr()))\n",
    "plt.savefig(\"heat_map_corr.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Conclusions:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 New feature inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Outlier analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_enc.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuos_f = list(df_enc.select_dtypes('float64'))\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10, 4))\n",
    "\n",
    "col=0\n",
    "for each in continuos_f:\n",
    "    sns.boxplot(ax = ax[col], data = df_enc, x=each)\n",
    "    col += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc_no = df_enc.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(x, feature_name, allow_neg=True):\n",
    "    q1, q3 = x.quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    upper_lim = q3 + (iqr*1.5)\n",
    "    lower_lim = q1 - (iqr*1.5) if allow_neg else max(0, q1 - (iqr * 1.5))\n",
    "\n",
    "    x = x.apply(lambda x: upper_lim if (x > upper_lim) else (lower_lim if (x < lower_lim) else x))\n",
    "\n",
    "    filename = f'../data/interim/outliers_lims_{feature_name}.json'\n",
    "    json.dump({'upper_lim': upper_lim, 'lower_lim': lower_lim}, open(filename, 'w'))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_outliers_with_neg = []\n",
    "f_outliers_no_neg = []\n",
    "\n",
    "for each in continuos_f:\n",
    "    if df_enc[each].min() < 0:\n",
    "        f_outliers_with_neg.append(each)\n",
    "    f_outliers_no_neg.append(each)\n",
    "\n",
    "for feature in f_outliers_with_neg:\n",
    "    df_enc_no[feature] = remove_outliers(df_enc_no[feature], feature)\n",
    "\n",
    "for feature in f_outliers_no_neg:\n",
    "    df_enc_no[feature] = remove_outliers(df_enc_no[feature], feature, allow_neg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Split train/test of both Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(target, df, test_size=0.2, random_state=123):\n",
    "    X = df.drop(columns=target)\n",
    "    y = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_with_outliers, X_test_with_outliers, y_train, y_test = split('Outcome', df_enc)\n",
    "X_train_without_outliers, X_test_without_outliers, _, _ = split('Outcome', df_enc_no)\n",
    "\n",
    "X_train_with_outliers.to_csv('../data/processed/X_train_with_outliers.csv', index=False)\n",
    "X_test_with_outliers.to_csv('../data/processed/X_test_with_outliers.csv', index=False)\n",
    "X_train_without_outliers.to_csv('../data/processed/X_train_without_outliers.csv', index=False)\n",
    "X_test_without_outliers.to_csv('../data/processed/X_test_without_outliers.csv', index=False)\n",
    "\n",
    "y_train.to_csv('../data/processed/y_train.csv', index=False)\n",
    "y_test.to_csv('../data/processed/y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_with_outliers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(X_train, X_test, reference: str):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    X_train_norm = scaler.transform(X_train)\n",
    "    X_train_norm = pd.DataFrame(X_train_norm, index=X_train.index, columns=X_train.columns)\n",
    "\n",
    "    X_test_norm = scaler.transform(X_test)\n",
    "    X_test_norm = pd.DataFrame(X_test_norm, index=X_test.index, columns=X_test.columns)\n",
    "\n",
    "    dump(scaler, open(f'../data/processed/normalized_{reference}.sav', 'wb'))\n",
    "\n",
    "    return X_train_norm, X_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_with_outliers_norm, X_test_with_outliers_norm = norm(X_train_with_outliers, X_test_with_outliers, 'with_outliers')\n",
    "X_train_without_outliers_norm, X_test_without_outliers_norm = norm(X_train_without_outliers, X_test_without_outliers, 'without_outliers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Min-Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(X_train, X_test, reference: str):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    X_train_minmax = scaler.transform(X_train)\n",
    "    X_train_minmax = pd.DataFrame(X_train_minmax, index = X_train.index, columns=X_train.columns)\n",
    "\n",
    "    X_test_minmax = scaler.transform(X_test)\n",
    "    X_test_minmax = pd.DataFrame(X_test_minmax, index = X_test.index, columns=X_test.columns)\n",
    "    \n",
    "    dump(scaler, open(f'../data/processed/minmax_{reference}.sav', 'wb'))\n",
    "\n",
    "    return X_train_minmax, X_test_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_with_outliers_minmax, X_test_with_outliers_minmax = minmax(X_train_with_outliers, X_test_with_outliers, 'with_outliers')\n",
    "X_train_without_outliers_minmax, X_test_without_outliers_minmax = minmax(X_train_without_outliers, X_test_without_outliers, 'without_outliers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.1 Kselection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kselection(X_train, X_test, y_train, k, reference: str):\n",
    "    selection_model = SelectKBest(f_classif, k=k)\n",
    "    selection_model.fit(X_train, y_train)\n",
    "    cols = selection_model.get_support()\n",
    "\n",
    "    X_train_sel = pd.DataFrame(selection_model.transform(X_train), columns=X_train.columns.values[cols]) \n",
    "    X_test_sel = pd.DataFrame(selection_model.transform(X_test), columns=X_test.columns.values[cols])\n",
    "\n",
    "    dump(selection_model, open(f'../data/processed/selection_model_{reference}.sav', 'wb'))\n",
    "\n",
    "    return X_train_sel, X_test_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_with_outliers_sel, X_test_with_outliers_sel = kselection(X_train_with_outliers, X_test_with_outliers, y_train, 'all', 'with_outliers')\n",
    "X_train_without_outliers_sel, X_test_without_outliers_sel = kselection(X_train_without_outliers, X_test_without_outliers, y_train, 'all', 'without_outliers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.2 Applying the columns filter (kselection) to the normalized and minmax scaled data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_with_outliers_norm_sel = X_train_with_outliers_norm[X_train_with_outliers_sel.columns]\n",
    "X_train_without_outliers_norm_sel = X_train_without_outliers_norm[X_train_with_outliers_sel.columns]\n",
    "\n",
    "X_test_with_outliers_norm_sel = X_test_with_outliers_norm[X_test_with_outliers_sel.columns]\n",
    "X_test_without_outliers_norm_sel = X_test_without_outliers_norm[X_test_with_outliers_sel.columns]\n",
    "\n",
    "X_train_with_outliers_minmax_sel = X_train_with_outliers_minmax[X_train_with_outliers_sel.columns]\n",
    "X_train_without_outliers_minmax_sel = X_train_without_outliers_minmax[X_train_without_outliers_sel.columns]\n",
    "\n",
    "X_test_with_outliers_minmax_sel = X_test_with_outliers_minmax[X_test_with_outliers_sel.columns]\n",
    "X_test_without_outliers_minmax_sel = X_test_without_outliers_minmax[X_test_without_outliers_sel.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7.2 Saving the CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_train = {\n",
    "    'X_train_with_outliers_sel': X_train_with_outliers_sel,\n",
    "    'X_train_without_outliers_sel': X_train_without_outliers_sel,\n",
    "    'X_train_with_outliers_norm_sel': X_train_with_outliers_norm_sel,\n",
    "    'X_train_without_outliers_norm_sel': X_train_without_outliers_norm_sel,\n",
    "    'X_train_with_outliers_minmax_sel': X_train_with_outliers_minmax_sel,\n",
    "    'X_train_without_outliers_minmax_sel': X_train_without_outliers_minmax_sel \n",
    "}\n",
    "\n",
    "dfs_test = {\n",
    "    'X_test_with_outliers_sel': X_test_with_outliers_sel,\n",
    "    'X_test_without_outliers_sel': X_test_without_outliers_sel,\n",
    "    'X_test_with_outliers_norm_sel': X_test_with_outliers_norm_sel,\n",
    "    'X_test_without_outliers_norm_sel': X_test_without_outliers_norm_sel,\n",
    "    'X_test_with_outliers_minmax_sel': X_test_with_outliers_minmax_sel,\n",
    "    'X_test_without_outliers_minmax_sel': X_test_without_outliers_minmax_sel    \n",
    "}\n",
    "\n",
    "for name, df in dfs_train.items():\n",
    "    df.to_csv(f\"../data/processed/{name}.csv\", index=False)\n",
    "\n",
    "for name, df in dfs_test.items(): \n",
    "    df.to_csv(f'../data/processed/{name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = [], []\n",
    "\n",
    "for name, df in dfs_train.items():\n",
    "    train.append(df)\n",
    "for name, df in dfs_test.items():\n",
    "    test.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 {Model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for index in range(len(train)):\n",
    "    model = \"????????\"\n",
    "    train_df = train[index]\n",
    "    model.fit(train_df, y_train)\n",
    "    y_test_pred = model.predict(test[index])\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            'index': index,\n",
    "            'df_train': list(dfs_train.keys())[index],\n",
    "            'Accuracy Score': round(accuracy_score(y_test, y_test_pred),4)         \n",
    "        }\n",
    "    )\n",
    "\n",
    "results = sorted(results, key=lambda x: x['Accuracy Score'], reverse=True)\n",
    "best_ind = results[0]['index']\n",
    "best_df_train = results[0]['df_train']\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Our best dataframe for our model is {best_df_train}, with an Accuracy Score of {results[0][\"Accuracy Score\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"?????\":\"?????\"\n",
    "}\n",
    "model = \"??????\"\n",
    "model.fit(dfs_train.get(best_df_train), y_train)\n",
    "grid = GridSearchCV(model, hyperparams, scoring = \"accuracy\", cv = 3)\n",
    "grid.fit(dfs_train.get(best_df_train), y_train)\n",
    "print(f'The best hyperparameters are: {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid = \"MODEL(HYPERPARAMETERS)\"\n",
    "model_grid.fit(dfs_train.get(best_df_train), y_train)\n",
    "y_pred = model_grid.predict(dfs_test.get(list(dfs_test)[best_ind]))\n",
    "model_grid_accuracy = round(accuracy_score(y_test, y_pred),4)\n",
    "print(f'The model accuracy with the hyperparameters is: {model_grid_accuracy*100}%, an increase of {round(model_grid_accuracy-(results[0][\"Accuracy Score\"]),4)*100}% vs the default model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
